## Урок 3A: Что такое генеративный ИИ? (Глубокое погружение)

Оригинальное видео по ссылке: https://www.youtube.com/watch?v=RyvXxApfHkk&list=PLf2m23nhTg1NjL3-jL3s0qZCYzO07ZQPv&index=5

Привет, меня зовут Дрю Бент, и я преподаватель, программист и член технического персонала в компании Anthropic. Добро пожаловать в наше исследование генеративного искусственного интеллекта. В этом видео мы погрузимся в то, что на самом деле представляет собой генеративный ИИ, как он работает под капотом, и в технологические прорывы, которые сделали возможными эти системы. Возможно, вы ежедневно взаимодействуете с генеративным ИИ, не до конца понимая, что происходит за кулисами. Давайте это изменим.

### Что такое генеративный ИИ?

Генеративный ИИ относится к системам искусственного интеллекта, которые могут создавать новый контент, а не просто анализировать существующие данные. Например, в то время как традиционный ИИ может классифицировать электронные письма как спам или не спам на основе паттернов, генеративный ИИ может написать для вас совершенно новое электронное письмо. Первый подход анализирует и категоризирует, второй создает что-то новое, чего раньше не существовало. Это представляет собой фундаментальный сдвиг в возможностях ИИ.

### Большие языковые модели

Большие языковые модели, или LLM, такие как модели Claude от Anthropic, являются выдающимся типом генеративного ИИ. Они называются языковыми моделями, потому что они обучены предсказывать и генерировать человеческий язык, и большими, потому что они содержат миллиарды параметров — математических значений, которые определяют, как модель обрабатывает информацию, что-то вроде синаптических соединений в вашем мозгу.

### Три ключевых фактора развития

Путь к современному генеративному ИИ не был внезапным. Он включал в себя три важнейших разработки, которые объединились в нужное время:

**Первое:** Алгоритмические и архитектурные прорывы, которые кардинально изменили способ обучения систем ИИ. Хотя нейронные сети существовали концептуально десятилетиями, разработка архитектуры трансформера в 2017 году стала переломным моментом. Эта архитектура превосходно обрабатывает последовательности текста, сохраняя при этом связи между словами в длинных отрывках, что критически важно для понимания языка в контексте.

**Второе:** Взрыв цифровых данных предоставил необходимое сырье для обучения. Современные LLM, такие как Claude, учатся из разнообразных источников, таких как веб-сайты, репозитории кода и другие тексты, которые представляют человеческие знания и коммуникацию. Эта обширная мозаика информации помогает моделям развивать широкое и нюансированное понимание как языка, так и концепций.

**Третье:** Массивное увеличение вычислительной мощности сделало возможным обучение этих сложных моделей на всех этих данных. Специализированное оборудование, такое как GPU (графические процессоры) и TPU (тензорные процессоры), вместе с распределенными вычислительными сетями, часто называемыми кластерами, обеспечивают обработку, которая была бы невозможна всего несколько лет назад.

### Законы масштабирования и эмерджентные способности

Сочетание этих трех факторов привело к важному открытию, известному как законы масштабирования. Эти эмпирические находки показали, что по мере роста моделей и обучения на большем количестве данных с большей вычислительной мощностью их производительность улучшалась предсказуемым образом. Что еще более удивительно, исследователи обнаружили, что совершенно новые способности начали появляться по мере роста этих моделей — способности, которые никто явно не программировал, такие как пошаговое рассуждение через проблемы или адаптация к новым задачам с минимальными инструкциями.

### Как работают системы под капотом

Давайте заглянем под капот того, как на самом деле работают эти системы. Во время первоначального обучения, также называемого предварительным обучением, LLM, такие как Claude, анализируют паттерны в миллиардах текстовых примеров. Представьте себе чтение каждого веб-сайта и каждого текста, который вы можете найти, не просто для поглощения информации, но для понимания статистических связей между словами, фразами и концепциями. На этом этапе модель по сути строит что-то вроде сложной карты языка и знаний.

Этот процесс предварительного обучения включает показ модели текста и просьбу предсказать, что будет дальше. Через множество итераций модель постепенно совершенствует свои предсказания, изучая паттерны, которые делают язык связным и осмысленным.

### Дообучение и развертывание

После предварительного обучения модели проходят дополнительное обучение, называемое дообучением, где они учатся следовать инструкциям, предоставлять полезные ответы и, что важно, избегать генерации вредного контента. Это часто включает человеческую обратную связь для улучшения производительности модели, а также обучение с подкреплением, которое использует награды и штрафы для формирования поведения модели в направлении большей полезности, честности и безвредности.

В случае моделей Anthropic, после обучения модели развертываются для вашего взаимодействия. Когда вы взаимодействуете с Claude или другой LLM, вы предоставляете промпт — текст, который модель читает, а затем продолжает на основе паттернов, которые она изучила во время обучения. Модель не извлекает заранее написанные ответы из базы данных; вместо этого она генерирует новый текст, который статистически следует из того, что вы написали.

### Контекстное окно

Существует также практическое ограничение на то, сколько информации LLM может рассматривать одновременно, известное как контекстное окно. Думайте об этом как о рабочей памяти ИИ. Контекстное окно включает ваши промпты, ответы ИИ и любую другую информацию, которой вы поделились в вашем разговоре. Хотя компании ИИ продолжают расширять контекстное окно, чтобы позволить более длинные контекстные документы и разговоры, эти ограничения напоминают нам, что эти системы не имеют неограниченного доступа к информации и не могут использовать контент за пределами своего текущего контекстного окна без специализированных инструментов, таких как веб-поиск.

### Три ключевые характеристики современного генеративного ИИ

Объединяя все это, три характеристики, которые делают современный генеративный ИИ таким мощным, включают:

**Во-первых:** Его способность обрабатывать огромные объемы информации во время обучения, позволяя ему изучать сложные и нюансированные паттерны в языке и знаниях.

**Во-вторых:** Его способность к контекстному обучению — LLM могут адаптироваться к новым задачам на основе инструкций или примеров в вашем промпте без необходимости дополнительного обучения.

**В-третьих:** Эмерджентные способности, которые возникают из масштаба — по мере роста этих моделей они развивают способности, которые не были явно в них заложены, иногда удивляя даже своих создателей.

В следующем видео мы исследуем, что эти системы могут и не могут делать хорошо, а также их наиболее распространенные или ценные применения.